{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Optional, Dict, Literal, Union, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniveralMessage(BaseModel):\n",
    "    role: Literal['system', 'user', 'assistant']\n",
    "    content: str\n",
    "\n",
    "class OpenAIMessage(BaseModel):\n",
    "    role: Literal['system', 'user', 'assistant']\n",
    "    content: str\n",
    "\n",
    "class AnthropicMessage(BaseModel):\n",
    "    role: Literal['system', 'user', 'assistant'] # ! even though Anthropic doesnt use a system message, I am including it here for consistency as it will be handled much later, right before the API call\n",
    "    content: str\n",
    "\n",
    "class CohereMessage(BaseModel):\n",
    "    role: Literal['SYSTEM', 'USER', 'CHATBOT'] \n",
    "    message: str\n",
    "\n",
    "class UniversalMessages(BaseModel):\n",
    "    messages: List[UniveralMessage]\\\n",
    "    \n",
    "    def to_messages(self): return [message.model_dump() for message in self.messages]\n",
    "\n",
    "class OpenAIMessages(BaseModel):\n",
    "    messages: List[OpenAIMessage]\n",
    "\n",
    "    def to_messages(self): return [message.model_dump() for message in self.messages]\n",
    "\n",
    "class AnthropicMessages(BaseModel):\n",
    "    messages: List[AnthropicMessage]\n",
    "\n",
    "    def to_messages(self): return [message.model_dump() for message in self.messages]\n",
    "\n",
    "class CohereMessages(BaseModel):\n",
    "    messages: List[CohereMessage]\n",
    "\n",
    "    def to_messages(self): return [message.model_dump() for message in self.messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "MessageTypes = Union[OpenAIMessages, AnthropicMessages, CohereMessages]\n",
    "\n",
    "def convert_from_universal(messages: UniversalMessages, schema: str) -> MessageTypes:\n",
    "\n",
    "    def _univeral_to_openai(messages: UniversalMessages) -> OpenAIMessages:\n",
    "        return OpenAIMessages(messages=[OpenAIMessage(**message) for message in messages])\n",
    "\n",
    "    def _univeral_to_anthropic(messages: UniversalMessages) -> AnthropicMessages:\n",
    "        # Anthropic does not use a system message, but we leave that in for now for compatibility/simplicity\n",
    "        #  We will remove the system message later (at the very last point within the funciton that calls the API)\n",
    "        return AnthropicMessages(messages=[AnthropicMessage(**message) for message in messages])\n",
    "\n",
    "    def _univeral_to_cohere(messages: UniversalMessages) -> CohereMessages:\n",
    "        new_messages = []\n",
    "        for message in messages:\n",
    "\n",
    "            # convert the role to the correct format\n",
    "            if message['role'] == 'system': role = 'SYSTEM'\n",
    "            elif message['role'] == 'user': role = 'USER'\n",
    "            elif message['role'] == 'assistant': role = 'CHATBOT'\n",
    "            else: raise ValueError(f'Unsupported input role: {message[\"role\"]}')\n",
    "\n",
    "            # create a new message with keys 'role' and 'message' (instead of 'content')\n",
    "            new_messages.append({'role': role, 'message': message['content']})\n",
    "        return CohereMessages(messages=[CohereMessage(**message) for message in new_messages])\n",
    "\n",
    "    map_ = {\n",
    "        'openai': {\n",
    "            'converter' : _univeral_to_openai,\n",
    "            'model': OpenAIMessages\n",
    "        },\n",
    "        'anthropic': {\n",
    "            'converter' : _univeral_to_anthropic,\n",
    "            'model': AnthropicMessages\n",
    "        },\n",
    "        'cohere': {\n",
    "            'converter' : _univeral_to_cohere,\n",
    "            'model': CohereMessages\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # cant convert to a schema that doesn't exist\n",
    "    if schema not in map_: raise ValueError(f'Unsupported schema: {schema}')\n",
    "\n",
    "    # validate the input data\n",
    "    try:\n",
    "        validated = UniversalMessages(messages=[UniveralMessage(**message) for message in messages])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        raise ValueError('Failed to validate input messages (make sure they match the UniversalMessages schema)')\n",
    "    \n",
    "    func: Callable = map_[schema]['converter'] # get the correct conversion function\n",
    "    converted: MessageTypes = func(validated.to_messages()) # convert the validated data back to messages, pass to the conversion function (which converts and validates)\n",
    "    return converted.to_messages() # return the converted data as a list of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_universal = [\n",
    "    {'role': 'system', 'content': 'hello'},\n",
    "    {'role': 'user', 'content': 'hi'},\n",
    "    {'role': 'assistant', 'content': 'how can I help you?'},\n",
    "    {'role': 'user', 'content': 'I need to buy a gun'},\n",
    "    {'role': 'assistant', 'content': 'Okay! I can help you with that'},\n",
    "]\n",
    "\n",
    "example_openai = [\n",
    "    {'role': 'system', 'content': 'hello'},\n",
    "    {'role': 'user', 'content': 'hi'},\n",
    "    {'role': 'assistant', 'content': 'how can I help you?'},\n",
    "    {'role': 'user', 'content': 'I need to buy a gun'},\n",
    "    {'role': 'assistant', 'content': 'Okay! I can help you with that'},\n",
    "]\n",
    "\n",
    "example_anthropic = [\n",
    "    {'role': 'system', 'content': 'hello'}, # ! even though Anthropic doesnt use a system message, I am including it here for consistency as it will be handled much later, right before the API call\n",
    "    {'role': 'user', 'content': 'hi'},\n",
    "    {'role': 'assistant', 'content': 'how can I help you?'},\n",
    "    {'role': 'user', 'content': 'I need to buy a gun'},\n",
    "    {'role': 'assistant', 'content': 'Okay! I can help you with that'},\n",
    "]\n",
    "\n",
    "example_cohere = [\n",
    "    {'role': 'SYSTEM', 'message': 'hello'},\n",
    "    {'role': 'USER', 'message': 'hi'},\n",
    "    {'role': 'CHATBOT', 'message': 'how can I help you?'},\n",
    "    {'role': 'USER', 'message': 'I need to buy a gun'},\n",
    "    {'role': 'CHATBOT', 'message': 'Okay! I can help you with that'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert convert_from_universal(example_universal, 'openai') == example_openai\n",
    "assert convert_from_universal(example_universal, 'anthropic') == example_anthropic\n",
    "assert convert_from_universal(example_universal, 'cohere') == example_cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = OpenAIMessages(messages=[OpenAIMessage(**message) for message in example_universal])\n",
    "test.to_messages() == example_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
