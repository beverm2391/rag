{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any, Optional, Union\n",
    "from pydantic import BaseModel\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from autorest.config import GenerativeConfig\n",
    "from autorest.examples import pydantic_model_example, database_model_example\n",
    "from lib.generators import GeneratorAsync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/Users/beneverman/Documents/Code/Tekmir/case-management-pipeline/case_management_pipeline/projects/api-hub\"\n",
    "db_models = f\"api_hub/database/models.py\"\n",
    "routes_dir = f\"api_hub/api/v1/routes/\"\n",
    "db_repos = f\"api_hub/database/repositories/\"\n",
    "pydantic_models = f\"api_hub/api/models.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GenerativeConfig(root_dir=ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joining relative path to root dir /Users/beneverman/Documents/Code/Tekmir/case-management-pipeline/case_management_pipeline/projects/api-hub\n"
     ]
    }
   ],
   "source": [
    "test = config.get_db_models(db_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes = os.listdir(os.path.join(ROOT_DIR, routes_dir)) \n",
    "routes = [r for r in routes if not r.startswith(\"__\")]\n",
    "paths = [os.path.join(ROOT_DIR, routes_dir, route) for route in routes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratedPydanticModel(BaseModel):\n",
    "    table_name: str\n",
    "    imports: str\n",
    "    code: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PydanticModelGenerator(GeneratorAsync):\n",
    "    def __init__(self, model: str = None, debug: bool = False):\n",
    "        super().__init__(\n",
    "            GeneratedPydanticModel,\n",
    "            system_prompt=\"You are designed to take in user instructons and answher the user's request concisely with only code and nothing but code.\",\n",
    "            model=model,\n",
    "            debug=debug,\n",
    "        )\n",
    "\n",
    "    async def generate(\n",
    "        self, one_or_many_queries: Union[List[str], str], model: str = None\n",
    "    ):\n",
    "        def _make_prompt(user_insturctions: str):\n",
    "            intructions = f\"\"\"\n",
    "            INSTRUCITONS:\n",
    "            Your job is to generate valid pydantic models according to the newest documentation based on the user's request.\n",
    "            Always output valid code and nothing but code.\n",
    "            You output imports separately from the rest of the code.\n",
    "            Always follow the example provided in the output if you are unsure of anything.\n",
    "\n",
    "            Formatting Rules:\n",
    "            - If a field can be missing from the database table without breaking the schema, use the Optional[] type hint in the Pydantic model.\n",
    "\n",
    "            Import Rules:\n",
    "            - Always include every necessary import.\n",
    "            - You can combine imports on the same line if they are from the same module.\n",
    "            - Import the UUID type as follows 'from uuid import UUID'\n",
    "            - Import ConfigDict as follows 'from pydantic import ConfigDict'\n",
    "\n",
    "            \"\"\"\n",
    "            example = f\"\"\"\n",
    "            EXAMPLE DB MODEL (Input)\n",
    "\n",
    "            {database_model_example}\n",
    "            \n",
    "            EXAMPLE PYDANTIC MODEL (Output)\n",
    "\n",
    "            {pydantic_model_example}\n",
    "            \"\"\"\n",
    "            query = f\"{intructions}\\n{example}\\nUSER INSTRUCTIONS:\\n{user_insturctions}\\nOUTPUT:\"\n",
    "            return query\n",
    "\n",
    "        def _handle_input(one_or_many_queries: Union[List[str], str]):\n",
    "            \"\"\"A function to handle the user input and return the list of prompts to be passed to the generator\"\"\"\n",
    "            if type(one_or_many_queries) == str:\n",
    "                return [\n",
    "                    _make_prompt(one_or_many_queries)\n",
    "                ]  # if user passes a string (one query) (we must still reuturn a list even though its one query)\n",
    "            elif type(one_or_many_queries == list):\n",
    "                return [\n",
    "                    _make_prompt(query) for query in one_or_many_queries\n",
    "                ]  # if user passes a list of queries\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Expected str or list, got {type(one_or_many_queries)}\"\n",
    "                )\n",
    "\n",
    "        queries = _handle_input(one_or_many_queries)\n",
    "        return await super().generate(queries, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing OpenAI Client...\n",
      "Model: gpt-4-turbo\n",
      "Model Var: gpt-4-turbo-preview\n",
      "Max Tokens: 4096\n",
      "Input Tokens: 123903\n",
      "Generating 1 queries...\n",
      "Task id: 0 in: 12.87s\n",
      "1 of 1 tasks completed\n",
      "Total time: 12.87s\n",
      "Error count: 0\n"
     ]
    }
   ],
   "source": [
    "model_generator = PydanticModelGenerator(model='gpt-4-turbo', debug=True)\n",
    "res = await model_generator.generate(test['MedicalInjury'])\n",
    "res = res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from pydantic import BaseModel, ConfigDict\n",
      "from typing import Optional\n",
      "from uuid import UUID\n",
      "from datetime import date\n",
      "from enum import Enum\n",
      "\n",
      "class DatePrecisionEnum(str, Enum):\n",
      "    Year = 'Year'\n",
      "    Month = 'Month'\n",
      "    Day = 'Day'\n",
      "    Unknown = 'Unknown'\n",
      "class MedicalInjurySchema(BaseModel):\n",
      "    id: UUID\n",
      "    injury_id: UUID\n",
      "    onset_date: Optional[date]\n",
      "    onset_date_precision: Optional[DatePrecisionEnum]\n",
      "    onset_state: Optional[str]\n",
      "    is_diagnosed: Optional[bool] = False\n",
      "    diagnosis_date: Optional[date]\n",
      "    diagnosis_date_precision: Optional[DatePrecisionEnum]\n",
      "    diagnosis_state: Optional[str]\n",
      "    diagnosis_provider_id: Optional[UUID]\n",
      "    injury_severity: Optional[str]\n",
      "    medical_injury_sub_type: Optional[str]\n",
      "\n",
      "    class Config(ConfigDict):\n",
      "        from_attributes = True # this is the updated way to use the from_orm method\n",
      "        use_enum_values = True # this is for the Enum values to be used instead of the index\n"
     ]
    }
   ],
   "source": [
    "imports, code = res.imports, res.code\n",
    "total = f\"{imports}\\n{code}\"\n",
    "\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegeneratedCode(BaseModel):\n",
    "    code: str\n",
    "    cause_of_error: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 58 (731300448.py, line 62)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[95], line 62\u001b[0;36m\u001b[0m\n\u001b[0;31m    def retry(self):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 58\n"
     ]
    }
   ],
   "source": [
    "class CodeRegenerator(GeneratorAsync):\n",
    "    def __init__(self, model: str = None, debug: bool = False):\n",
    "        super().__init__(\n",
    "            RegeneratedCode,\n",
    "            system_prompt=\"You are designed to take in user instructions and answer the user's request concisely with only code and nothing but code.\",\n",
    "            model=model,\n",
    "            debug=debug,\n",
    "        )\n",
    "\n",
    "    async def generate(\n",
    "        self, one_or_many_queries: Union[List[str], str], model: str = None\n",
    "    ):\n",
    "        def _make_prompt(user_instructions: str):\n",
    "            instructions = f\"\"\"\n",
    "            INSTRUCTIONS:\n",
    "            Your job is to take in invalid code, brainstorm why it didn't work, fix it, and output only the fixed code.\n",
    "            Always output valid code and nothing but code.\n",
    "\n",
    "            Formatting Rules:\n",
    "            - Ensure all necessary imports are included.\n",
    "            - Maintain consistent code formatting and adhere to PEP 8 guidelines.\n",
    "            - Make sure to provide valid Pydantic models according to the latest documentation.\n",
    "\n",
    "            Import Rules:\n",
    "            - Always include every necessary import.\n",
    "            - You can combine imports on the same line if they are from the same module.\n",
    "            \"\"\"\n",
    "            query = f\"{instructions}\\nUSER INSTRUCTIONS:\\n{user_instructions}\\nOUTPUT:\"\n",
    "            return query\n",
    "\n",
    "        def _handle_input(one_or_many_queries: Union[List[str], str]):\n",
    "            \"\"\"A function to handle the user input and return the list of prompts to be passed to the generator.\"\"\"\n",
    "            if isinstance(one_or_many_queries, str):\n",
    "                return [_make_prompt(one_or_many_queries)]\n",
    "            elif isinstance(one_or_many_queries, list):\n",
    "                return [_make_prompt(query) for query in one_or_many_queries]\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Expected str or list, got {type(one_or_many_queries)}\"\n",
    "                )\n",
    "\n",
    "        queries = _handle_input(one_or_many_queries)\n",
    "        return await super().generate(queries, model)\n",
    "\n",
    "class DynamicOutputValidator:\n",
    "    def __init__(self, code: str, retries: int = 2):\n",
    "        self.code: List[str] = [code]\n",
    "        self.retries = retries\n",
    "        self.generator = CodeRegenerator(model='gpt-4-turbo')\n",
    "\n",
    "    async def regenerate(self):\n",
    "        for i in range(self.retries):\n",
    "            current_best_code = self.code[-1]\n",
    "            try:\n",
    "                exec(current_best_code)\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                print(f\"Regenerating code... try {i+1} / {self.retries}\")\n",
    "                prompt = f\"This error was thrown by the code below:\\n{str(e)}\\nCode:\\n{code}\"\n",
    "                res: List[RegeneratedCode] = await self.generator.generate(prompt)\n",
    "                new_best_code = res[0].code\n",
    "                self.code.append(new_best_code)\n",
    "        return None # we failed to regenerate the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
